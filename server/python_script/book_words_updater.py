#!/usr/bin/env python3
"""
åˆä½µä¸¦æ›´æ–° book_words è³‡æ–™åº«
å°‡ lesson_words.xlsx çš„æ­£ç¢ºè³‡æ–™èˆ‡ tsl_app.book_words.csv åˆä½µï¼Œ
ä¿ç•™æ­£ç¢ºçš„åœ–ç‰‡é€£çµå’Œåˆ†ç´šè³‡è¨Šï¼Œé‡æ–°åŒ¯å…¥è³‡æ–™åº«
"""

import pandas as pd
import pymongo
from datetime import datetime
import re
import os
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

class BookWordsUpdater:
    def __init__(self):
        # MongoDB é€£æ¥ (éœ€è¦è¨­å®šæ‚¨çš„é€£æ¥å­—ä¸²)
        self.mongo_url = os.getenv('MONGO_URL', 'mongodb://localhost:27017/tsl_app')
        self.client = None
        self.db = None
        self.collection = None
        
    def connect_mongodb(self):
        """é€£æ¥ MongoDB"""
        try:
            self.client = pymongo.MongoClient(self.mongo_url)
            self.db = self.client['tsl_app']  # å‡è¨­è³‡æ–™åº«åç¨±æ˜¯ tsl_app
            self.collection = self.db['book_words']
            print("âœ… MongoDB é€£æ¥æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ MongoDB é€£æ¥å¤±æ•—: {e}")
            return False
    
    def load_data_files(self):
        """è¼‰å…¥å…©å€‹è³‡æ–™æª”æ¡ˆ"""
        try:
            print("ğŸ“– è¼‰å…¥è³‡æ–™æª”æ¡ˆ...")
            
            # è¼‰å…¥ç¾æœ‰çš„ book_words è³‡æ–™
            self.book_words_df = pd.read_csv('tsl_app.book_words.csv')
            print(f"   tsl_app.book_words.csv: {len(self.book_words_df)} ç­†è³‡æ–™")
            
            # è¼‰å…¥æ­£ç¢ºçš„ lesson_words è³‡æ–™
            self.lesson_words_df = pd.read_excel('lesson_words.xlsx')
            print(f"   lesson_words.xlsx: {len(self.lesson_words_df)} ç­†è³‡æ–™")
            
            print("ğŸ“‹ lesson_words.xlsx æ¬„ä½:")
            for col in self.lesson_words_df.columns:
                print(f"   - {col}")
                
            print("ğŸ“‹ book_words.csv æ¬„ä½:")
            for col in self.book_words_df.columns:
                print(f"   - {col}")
            
            return True
            
        except Exception as e:
            print(f"âŒ è¼‰å…¥è³‡æ–™æª”æ¡ˆå¤±æ•—: {e}")
            return False
    
    def merge_and_clean_data(self):
        """åˆä½µä¸¦æ¸…ç†è³‡æ–™"""
        try:
            print("\nğŸ”§ é–‹å§‹åˆä½µå’Œæ¸…ç†è³‡æ–™...")
            
            # ä»¥ lesson_words ç‚ºä¸»è¦è³‡æ–™æºï¼Œå› ç‚ºå®ƒçš„é€£çµæ˜¯æ­£ç¢ºçš„
            merged_data = []
            
            for _, lesson_row in self.lesson_words_df.iterrows():
                title = str(lesson_row.get('title', '')).strip()
                
                if not title or title == 'nan':
                    continue
                
                # åœ¨ book_words ä¸­å°‹æ‰¾å°æ‡‰çš„è©å½™
                matching_book_words = self.book_words_df[
                    self.book_words_df['title'].str.strip() == title
                ]
                
                # å»ºç«‹åˆä½µå¾Œçš„è¨˜éŒ„
                merged_record = {
                    'volume': int(lesson_row.get('volume', 1)),
                    'lesson': int(lesson_row.get('lesson', 1)),
                    'title': title,
                    'page': lesson_row.get('page'),
                    'image_url': lesson_row.get('image_url', ''),
                    'video_url': lesson_row.get('video_url', ''),
                    'created_by': 'admin',
                    'created_at': datetime.now().isoformat(),
                    'updated_at': datetime.now().isoformat(),
                }
                
                # å¦‚æœåœ¨ book_words ä¸­æ‰¾åˆ°åŒ¹é…ï¼Œä½¿ç”¨å…¶åˆ†ç´šå’Œåˆ†é¡è³‡è¨Š
                if not matching_book_words.empty:
                    book_row = matching_book_words.iloc[0]
                    
                    # ä½¿ç”¨ book_words çš„åˆ†ç´šåˆ†é¡è³‡è¨Š
                    merged_record.update({
                        'level': book_row.get('level', 'åˆç´š'),
                        'theme': book_row.get('theme'),
                        'category': book_row.get('category', 'ç¶œåˆ'),
                        'content': title,  # å…§å®¹å°±æ˜¯æ¨™é¡Œ
                        'context': book_row.get('context', 'home_school'),
                        'frequency': book_row.get('frequency', 'medium'),
                        'learning_level': book_row.get('learning_level', 'beginner'),
                        'categories': [
                            book_row.get('categories[0]', ''),
                            book_row.get('categories[1]', ''),
                            book_row.get('categories[2]', '')
                        ],
                        'searchable_text': f"{title} {book_row.get('categories[0]', '')} {book_row.get('learning_level', 'beginner')} {book_row.get('context', 'home_school')}"
                    })
                else:
                    # å¦‚æœæ²’æœ‰æ‰¾åˆ°åŒ¹é…ï¼Œè¨­å®šé è¨­å€¼
                    learning_level = self.determine_learning_level(merged_record['volume'])
                    category = self.determine_category(title)
                    
                    merged_record.update({
                        'level': 'åˆç´š' if merged_record['volume'] <= 3 else 'ä¸­ç´š' if merged_record['volume'] <= 7 else 'é«˜ç´š',
                        'theme': None,
                        'category': category,
                        'content': title,
                        'context': 'home_school',
                        'frequency': 'medium',
                        'learning_level': learning_level,
                        'categories': [category, '', ''],
                        'searchable_text': f"{title} {category} {learning_level} home_school"
                    })
                
                merged_data.append(merged_record)
            
            self.merged_df = pd.DataFrame(merged_data)
            print(f"âœ… åˆä½µå®Œæˆï¼Œå…± {len(self.merged_df)} ç­†è³‡æ–™")
            
            return True
            
        except Exception as e:
            print(f"âŒ åˆä½µè³‡æ–™å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def determine_learning_level(self, volume):
        """æ ¹æ“šå†Šæ•¸æ±ºå®šå­¸ç¿’ç´šåˆ¥"""
        if volume <= 3:
            return 'beginner'
        elif volume <= 7:
            return 'intermediate'
        else:
            return 'advanced'
    
    def determine_category(self, title):
        """æ ¹æ“šè©å½™å…§å®¹åˆ¤æ–·åˆ†é¡"""
        # ç°¡å–®çš„åˆ†é¡é‚è¼¯ï¼Œå¯ä»¥æ ¹æ“šéœ€è¦æ“´å±•
        action_words = ['èµ·åºŠ', 'åˆ·ç‰™', 'æ´—è‡‰', 'ç©¿è¡£æœ', 'è®€æ›¸', 'å»', 'åƒ', 'å–', 'èµ°', 'è·‘', 'å', 'ç«™']
        emotion_words = ['é–‹å¿ƒ', 'é›£é', 'ç”Ÿæ°£', 'å®³æ€•', 'é©šè¨', 'æ„›', 'å–œæ­¡']
        family_words = ['çˆ¸çˆ¸', 'åª½åª½', 'å“¥å“¥', 'å§Šå§Š', 'å¼Ÿå¼Ÿ', 'å¦¹å¦¹', 'çˆºçˆº', 'å¥¶å¥¶']
        object_words = ['æ›¸', 'æ¡Œå­', 'æ¤…å­', 'æ¯å­', 'ç¢—', 'ç­·å­', 'è»Šå­', 'æˆ¿å­']
        
        if any(word in title for word in action_words):
            return 'æ—¥å¸¸å‹•ä½œ'
        elif any(word in title for word in emotion_words):
            return 'æƒ…æ„Ÿè¡¨é”'
        elif any(word in title for word in family_words):
            return 'äººç‰©é—œä¿‚'
        elif any(word in title for word in object_words):
            return 'ç‰©å“å·¥å…·'
        else:
            return 'ç¶œåˆ'
    
    def backup_and_clear_collection(self):
        """å‚™ä»½ä¸¦æ¸…ç©ºç¾æœ‰é›†åˆ"""
        try:
            print("\nğŸ’¾ å‚™ä»½ç¾æœ‰è³‡æ–™...")
            
            # å‚™ä»½ç¾æœ‰è³‡æ–™
            existing_data = list(self.collection.find())
            if existing_data:
                backup_filename = f"book_words_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                import json
                with open(backup_filename, 'w', encoding='utf-8') as f:
                    json.dump(existing_data, f, ensure_ascii=False, indent=2, default=str)
                print(f"âœ… å‚™ä»½å®Œæˆ: {backup_filename}")
            
            # æ¸…ç©ºé›†åˆ
            result = self.collection.delete_many({})
            print(f"ğŸ—‘ï¸  å·²åˆªé™¤ {result.deleted_count} ç­†èˆŠè³‡æ–™")
            
            return True
            
        except Exception as e:
            print(f"âŒ å‚™ä»½å¤±æ•—: {e}")
            return False
    
    def insert_merged_data(self):
        """å°‡åˆä½µå¾Œçš„è³‡æ–™åŒ¯å…¥è³‡æ–™åº«"""
        try:
            print("\nğŸ“ åŒ¯å…¥æ–°è³‡æ–™...")
            
            # è½‰æ› DataFrame ç‚ºå­—å…¸åˆ—è¡¨
            records = self.merged_df.to_dict('records')
            
            # æ¸…ç† NaN å€¼
            for record in records:
                for key, value in record.items():
                    if pd.isna(value):
                        record[key] = None
            
            # æ‰¹é‡æ’å…¥
            result = self.collection.insert_many(records)
            print(f"âœ… æˆåŠŸåŒ¯å…¥ {len(result.inserted_ids)} ç­†è³‡æ–™")
            
            return True
            
        except Exception as e:
            print(f"âŒ åŒ¯å…¥è³‡æ–™å¤±æ•—: {e}")
            return False
    
    def generate_summary_report(self):
        """ç”Ÿæˆæ‘˜è¦å ±å‘Š"""
        try:
            print("\nğŸ“Š ç”Ÿæˆæ‘˜è¦å ±å‘Š...")
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_filename = f"book_words_update_report_{timestamp}.txt"
            
            with open(report_filename, 'w', encoding='utf-8') as f:
                f.write(f"Book Words è³‡æ–™åº«æ›´æ–°å ±å‘Š\n")
                f.write(f"æ›´æ–°æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write("=" * 50 + "\n\n")
                
                f.write(f"ç¸½è³‡æ–™ç­†æ•¸: {len(self.merged_df)}\n\n")
                
                # æŒ‰å†Šæ•¸çµ±è¨ˆ
                f.write("å„å†Šè©å½™æ•¸é‡:\n")
                volume_counts = self.merged_df['volume'].value_counts().sort_index()
                for volume, count in volume_counts.items():
                    f.write(f"  ç¬¬{volume}å†Š: {count}ç­†\n")
                
                f.write("\n")
                
                # æŒ‰åˆ†é¡çµ±è¨ˆ
                f.write("åˆ†é¡çµ±è¨ˆ:\n")
                category_counts = self.merged_df['category'].value_counts()
                for category, count in category_counts.items():
                    f.write(f"  {category}: {count}ç­†\n")
                
                f.write("\n")
                
                # å­¸ç¿’ç´šåˆ¥çµ±è¨ˆ
                f.write("å­¸ç¿’ç´šåˆ¥çµ±è¨ˆ:\n")
                level_counts = self.merged_df['learning_level'].value_counts()
                for level, count in level_counts.items():
                    f.write(f"  {level}: {count}ç­†\n")
                
                f.write("\n")
                
                # æœ‰åœ–ç‰‡é€£çµçš„çµ±è¨ˆ
                has_image = self.merged_df['image_url'].notna() & (self.merged_df['image_url'] != '')
                f.write(f"æœ‰åœ–ç‰‡é€£çµ: {has_image.sum()}ç­†\n")
                f.write(f"ç„¡åœ–ç‰‡é€£çµ: {len(self.merged_df) - has_image.sum()}ç­†\n")
            
            print(f"ğŸ“„ å ±å‘Šå·²ç”Ÿæˆ: {report_filename}")
            
            # è¼¸å‡ºåˆ°æ§åˆ¶å°
            print("\nğŸ“Š æ›´æ–°çµ±è¨ˆ:")
            print(f"   ç¸½è³‡æ–™ç­†æ•¸: {len(self.merged_df)}")
            print(f"   å„å†Šåˆ†ä½ˆ: {dict(volume_counts)}")
            print(f"   æœ‰åœ–ç‰‡é€£çµ: {has_image.sum()}/{len(self.merged_df)}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå ±å‘Šå¤±æ•—: {e}")
            return False
    
    def run_update_process(self):
        """åŸ·è¡Œå®Œæ•´çš„æ›´æ–°æµç¨‹"""
        print("ğŸ¯ é–‹å§‹ Book Words è³‡æ–™åº«æ›´æ–°æµç¨‹...")
        
        # 1. è¼‰å…¥è³‡æ–™æª”æ¡ˆ
        if not self.load_data_files():
            return False
        
        # 2. åˆä½µå’Œæ¸…ç†è³‡æ–™
        if not self.merge_and_clean_data():
            return False
        
        # 3. é€£æ¥è³‡æ–™åº«
        if not self.connect_mongodb():
            print("âš ï¸  ç„¡æ³•é€£æ¥ MongoDBï¼Œå°‡åªç”Ÿæˆåˆä½µå¾Œçš„æª”æ¡ˆ")
            # ä»ç„¶å¯ä»¥ç”Ÿæˆåˆä½µå¾Œçš„è³‡æ–™æª”æ¡ˆ
            self.save_merged_data_file()
            self.generate_summary_report()
            return True
        
        # 4. å‚™ä»½ä¸¦æ¸…ç©ºç¾æœ‰è³‡æ–™
        if not self.backup_and_clear_collection():
            return False
        
        # 5. åŒ¯å…¥æ–°è³‡æ–™
        if not self.insert_merged_data():
            return False
        
        # 6. ç”Ÿæˆå ±å‘Š
        self.generate_summary_report()
        
        # 7. å„²å­˜åˆä½µå¾Œçš„æª”æ¡ˆ
        self.save_merged_data_file()
        
        print("\nğŸ‰ è³‡æ–™åº«æ›´æ–°å®Œæˆï¼")
        return True
    
    def save_merged_data_file(self):
        """å„²å­˜åˆä½µå¾Œçš„è³‡æ–™æª”æ¡ˆ"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # å„²å­˜ç‚º CSV
            csv_filename = f"book_words_merged_{timestamp}.csv"
            self.merged_df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
            print(f"ğŸ’¾ åˆä½µå¾Œè³‡æ–™å·²å„²å­˜: {csv_filename}")
            
            # å„²å­˜ç‚º Excel
            excel_filename = f"book_words_merged_{timestamp}.xlsx"
            self.merged_df.to_excel(excel_filename, index=False)
            print(f"ğŸ’¾ åˆä½µå¾Œè³‡æ–™å·²å„²å­˜: {excel_filename}")
            
        except Exception as e:
            print(f"âŒ å„²å­˜æª”æ¡ˆå¤±æ•—: {e}")

if __name__ == "__main__":
    updater = BookWordsUpdater()
    updater.run_update_process()
